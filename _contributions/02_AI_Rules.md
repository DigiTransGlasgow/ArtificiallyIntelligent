---
title: AI Rules
layout: default
---

# AI Rules?
## Jon Rogers and Andrew Prescott

How far has artificial intelligence advanced? It is difficult to judge. One problem is that a lot of the most dramatic advances are being driven by commercial interests, and it is impossible to penetrate the veils of commercial sensitivity to find out what is going on. Another issue is that there is a distinction between the ability to use massive processing power to crunch data at great speed and in new ways, which might not be regarded as true AI, and the use of methods like neural networks to create greater machine autonomy and creativity. Our use of terms like artificial intelligence is often too sweeping. There's a distinction between crunching data on a bigger and bigger scale, and developing computational methods to mimic intelligence and creativity.

Thinking about artificial intelligence needs to go hand in hand with work on the nature of consciousness, perception and creativity. We need to bring words like wisdom and knowledge - maybe even the soul - back into the discussion. The most dramatic triumphs of AI are limited in their scope and don't yet reflect the range of human creativity and endeavour. A computer can learn to play a game like 'Go' so as to beat humans, but can it listen to a radio broadcast at the same time, or answer random questions from passers by? When will computers learn to dream? Intelligence is often about the ability to deal with and process the multiple and the unexpected. Recreating that ability is interesting as an engineering problem, but how far do we actually want computers to replicate that ability to multitask?

If computational processing poses limitations, this also raises questions as to what we want our friends electric to do, and what role we want them to play in our lives. There has already for many years been a lively debate about the ethical treatment of robots. Will we treat our robots as slaves, or will we assign them their own agency. What do we make of their commercial servitude? Is Alexa simply a company slave? How ethical is your relationship with her?

It is assumed that threats from AI come from its ability to become increasingly more proficient and autonomous, and by a potential ability to outflank and outthink humans. However, there are already enough implementations at the low end of AI which offer challenging privacy, security and wellbeing issues. These are supercharged and mane more worrying by commercial hookups. When Hyundai incorporates Alexa in its cars, technically relatively simple, all sort of strange threats emerge.

Work is the field where the advent of artificial intelligence may seem most threatening. Press reports warn of the jobs that will be wiped out by the growth of automated procedures. In the past, it was mechanistic repetitive jobs that were most at risk - typing, shorthand, switchboard operators are some of the jobs that have disappeared in the past fifty years. The growth of online shopping has recently disrupted employment patterns in retail. What seems to give current discussion around artificial intelligence its edge is the assumption that professional jobs are at risk - that land transfer documents and contracts might in future be drawn up by bots rather than solicitors, that accountants might be replaced by machines, that even new stories could be generated by machine learning.

We cannot of course be sure of the future patterns of development. Mostof the success in robotic innovation to date has after all been inrepetitive mechanical tasks requiring precise movements, such as carassembly line operation. It is not too fanciful to imagine thathairdressing or manicures might be performed by robots.

However, what strikes us most about these anxieties over automation in work is the gendered and class assumptions lying behind them. The disappearance of jobs like the typist (a characteristically working class female role) is not thought to be a matter of great concern, but the threat to middle class professional positions like solicitors and accountants creates greater anxieties.

This theme also echoes the anxiety that AI will do something to you - that it is a force unleashed by technology that is somehow outside your control. This anxiety is reinforced by the claims of such celebrity commentators as Stephen Hawking and Elon Musk that AI is a threat to humanity.

However, artificial intelligence is not an unstoppable force of nature. We make it and we design what it does. It mirrors our prejudices and idiocies because of the way we design it. If we conceive of AI as a top-down cost cutting corporate instrument, it will become a threat. However, if we design AI differently, AI has the potential to make life more interesting and more fulfilling. The issue is how we achieve that. Some hints might be:-

-   Work from the bottom up.
-   Explore structures for co-creation.
-   Think about ethical frameworks for the development of AI.
-   Do we need to have AI job offsetting? That for every job that AI replaces, we create two more in other forms of paid work?
-   Do we need a clearer labelling of how things have been designed or created? This symphony was composed by AI? This scene was painted by Siri? This song was imagined by Alexa?
-   Decentralisation of AI is key to ensuring that cutting low paid jobs doesn't lead to increased riches for the few.
-   That we design products that are repairable by people
-   We foster/regulate a culture of local adaption of AI that ensures people are employed to work with the new tools AI produces to enhance and create new forms of independent culture.

Above all, we need to experiment with AI, and not simply take it as a given. Does our engagement with AI improve if we make AI devices that are more physical? That have knobs and dials to control and mediate our experience? How do we make the AI process more transparent?

We might also need to consider how we constitute value. Does work exist simply to produce goods and services or does it perform other functions? Work might be imagined as something that does more than produce goods and services cheaply and in a frictionless way. If we argue that work for example has an important social value, we might want to reimagine
its nature and scope.

For over two hundred years, the idea of the division of labour as a paradigm of efficient production has prevailed. Adam Smith in *The Wealth of Nations* (1776) explained how the manufacture of large number of pins was made feasible by the way in which each worker undertook one small part of the larger process. Our approach to automation has been profoundly affected by the concept of the division of labour.

This helps explain why manual tasks were those which were automated first. If mechanical and repetitive elements of the division of labour could be automated first, it would make the whole task simpler. AI doesn't represent a significant advance on this approach. The greater processing power and data availability simply means that tasks like the compilation of accounts or drafting of conveyances have now come within
the potential purview.

Maybe as AI progresses, the possibility of completely new ways of working will emerge which transcend the division of labour. We might revert to a more craft based approach which looks at tasks holistically. We might rethink what work is actually for. In order to do this, we need to surround our development of artificial intelligence with social models which will give us a more intimate relationship to the technology. We might look back to the guilds of the middle ages which sought to ensure a more holistic relationship between master, apprentice, customer and production. The way in which goods were produced reflected community consensus and understanding.

If the artificially intelligent world is one dominated by giant corporations and a top down approach to the technology in which individuals are seen as consumers rather than creators, then it will create a world of work dominated by massive inequalities, insecurities and social anxiety. However, if we use artificial intelligence to explore new possibilities of co-creation, sharing and rethinking the structure of production, we can reshape work in a way that makes our lives more satisfying and exciting.

Do you have an Echo dot? Try this experiment. Say 'Alexa tell me a joke' very quickly, so quickly that the blue light hasn't come on before you finish. Yet Alexa will still respond to the command even though she was asleep when you stated speaking.

Alexa is always on and always listening. She has to be, in order to be ready to receive your commands. It is no wonder that stories of Alexa and her sisters like Siri awaking unexpectedly and surprising their owners in various ways are legion.

And all these recordings from your house are sent to Amazon for processing and kept for posterity, as the terms and conditions make clear:

> Alexa is a continuously improving service that you control with your
> voice. Alexa streams audio to the cloud when you interact with Alexa.
> Alexa is always learning and getting smarter; Alexa updates through
> the cloud automatically to add new features and skills. To provide the
> Alexa service, personalize it, and improve our services, Amazon
> processes and retains your Alexa Interactions, such as your voice
> inputs, music playlists and your Alexa to-do and shopping lists, in
> the cloud.
>
> If you use a Third Party Service, we may exchange related information
> with that service, such as your zip code when you ask for the weather,
> your custom music stations, information about your Auxiliary Products,
> or the content of your requests.

It took us a while - too long - to realise what was happening to the data we were giving to Facebook. Privacy controversies are too often debates about closing stable doors when horses have bolted. While politicians were grilling Mark Zuckerberg, perhaps they should be wondering about voice. Maybe that will be the next big scandal. 

The more frictionless our interaction with smart devices the less we think about consent. Our consent when we talk to another human being is framed by our shared social training, the place where the interaction takes place and a mutual understanding of the legal system. Little of that applies when we have a conversation with Alexa. We are bound only by a set of terms and conditions imposed on both of us by Alexa's creator and true owner which we may not have read. This is a voice conversation unlike any other we may have - it can be freely recorded, stored, distributed, analysed and kept by third parties we may never have heard of.

We have got used (rather rudely and shockingly, particularly over the past year) to the idea that by giving information to packages like Facebook, we are being used and traded. The process of doing that with a keyboard or a phone has enough friction about it that we can retain a consciousness of what we are giving up. Voice reduces that level of awareness - as our conversations with Alexa feel like normal conversations, we are seduced by Alexa into forgetting how they will be used. Consent becomes invisible. If this is problematic enough with voice, then it starts to get even more difficult when we think about immersive haptic interfaces. Do I give consent when I touch?
